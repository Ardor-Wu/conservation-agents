{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GYM FISHING WITH PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_fishing\n",
    "\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using cpu device\nWrapping the env in a DummyVecEnv.\n"
    }
   ],
   "source": [
    "env = gym.make('fishing-v0')\n",
    "env.n_actions = 100\n",
    "model = PPO('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-----------------------------------------\n| time/                   |             |\n|    fps                  | 2133        |\n|    iterations           | 1           |\n|    time_elapsed         | 0           |\n|    total timesteps      | 2048        |\n| train/                  |             |\n|    approx_kl            | 0.003012917 |\n|    clip_fraction        | 0.219       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | -13         |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0432     |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0227     |\n|    value_loss           | 0.00283     |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 1346       |\n|    iterations           | 2          |\n|    time_elapsed         | 3          |\n|    total timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01343407 |\n|    clip_fraction        | 0.0625     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.05      |\n|    explained_variance   | -12.5      |\n|    learning_rate        | 0.0003     |\n|    loss                 | -0.0284    |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0225    |\n|    value_loss           | 0.00389    |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 1089        |\n|    iterations           | 3           |\n|    time_elapsed         | 5           |\n|    total timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.015005728 |\n|    clip_fraction        | 0.516       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.975      |\n|    explained_variance   | -20.6       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0484     |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0196     |\n|    value_loss           | 0.00459     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 1053        |\n|    iterations           | 4           |\n|    time_elapsed         | 7           |\n|    total timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010244732 |\n|    clip_fraction        | 0.453       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.879      |\n|    explained_variance   | -16.4       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0542     |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0136     |\n|    value_loss           | 0.00562     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 1009        |\n|    iterations           | 5           |\n|    time_elapsed         | 10          |\n|    total timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008683773 |\n|    clip_fraction        | 0.109       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.759      |\n|    explained_variance   | -29.6       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.005      |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.0141     |\n|    value_loss           | 0.00728     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 1005        |\n|    iterations           | 6           |\n|    time_elapsed         | 12          |\n|    total timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.008161223 |\n|    clip_fraction        | 0.219       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.673      |\n|    explained_variance   | -18.1       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00468     |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.00942    |\n|    value_loss           | 0.0084      |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 986          |\n|    iterations           | 7            |\n|    time_elapsed         | 14           |\n|    total timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0075854408 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.592       |\n|    explained_variance   | -26.9        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00998      |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00258     |\n|    value_loss           | 0.0101       |\n------------------------------------------\n---------------------------------------\n| time/                   |           |\n|    fps                  | 986       |\n|    iterations           | 8         |\n|    time_elapsed         | 16        |\n|    total timesteps      | 16384     |\n| train/                  |           |\n|    approx_kl            | 0.0053746 |\n|    clip_fraction        | 0.0938    |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -0.528    |\n|    explained_variance   | -29       |\n|    learning_rate        | 0.0003    |\n|    loss                 | 0.000211  |\n|    n_updates            | 80        |\n|    policy_gradient_loss | -0.00678  |\n|    value_loss           | 0.0117    |\n---------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 988          |\n|    iterations           | 9            |\n|    time_elapsed         | 18           |\n|    total timesteps      | 18432        |\n| train/                  |              |\n|    approx_kl            | 0.0065577617 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.454       |\n|    explained_variance   | -24.3        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0079       |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.00263     |\n|    value_loss           | 0.013        |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 973          |\n|    iterations           | 10           |\n|    time_elapsed         | 21           |\n|    total timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0060079154 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.41        |\n|    explained_variance   | -34.1        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00462      |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00355     |\n|    value_loss           | 0.0144       |\n------------------------------------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<stable_baselines3.ppo.ppo.PPO at 0x132ef6f10>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(1000) :\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}